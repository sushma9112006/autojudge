{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0841f8c3-3405-4b25-bbb7-5632ab5508db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description           0\n",
       "input_description     0\n",
       "output_description    0\n",
       "problem_class         0\n",
       "problem_score         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sparse_to_dense(x):\n",
    "    return x.toarray()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer,StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, VotingClassifier,RandomForestRegressor,HistGradientBoostingRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score,precision_recall_curve,mean_absolute_error, mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import clone\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#LOAD\n",
    "url = \"https://raw.githubusercontent.com/AREEG94FAHAD/TaskComplexityEval-24/refs/heads/main/problems_data.jsonl\"\n",
    "df = pd.read_json(url, lines=True)\n",
    "df = df.drop(columns=['sample_io', 'url', 'title'], errors='ignore')\n",
    "#df.sample(5)\n",
    "df.isnull().sum()\n",
    "#plt.bar(df['problem_class'].value_counts().index, df['problem_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6a9abc-6887-4626-a7b4-a87f6326f3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen HARD threshold (CV): 0.5384\n",
      "Accuracy: 0.5176184690157959\n",
      "[[ 80  20  53]\n",
      " [ 39 210 140]\n",
      " [ 41 104 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        easy       0.50      0.52      0.51       153\n",
      "        hard       0.63      0.54      0.58       389\n",
      "      medium       0.41      0.48      0.45       281\n",
      "\n",
      "    accuracy                           0.52       823\n",
      "   macro avg       0.51      0.52      0.51       823\n",
      "weighted avg       0.53      0.52      0.52       823\n",
      "\n",
      "Score MAE (test): 1.8084\n",
      "Score RMSE (test): 2.3504\n"
     ]
    }
   ],
   "source": [
    "targets = [\"problem_score\", \"problem_class\"]\n",
    "text_cols = [c for c in df.columns if c not in targets]\n",
    "df[\"full_text\"] = df[text_cols].fillna(\"\").astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = s.lower()\n",
    "    s = s.replace(\"≤\", \"<=\").replace(\"≥\", \">=\").replace(\"≠\", \"!=\")\n",
    "    s = re.sub(r\"[→⇒]\", \"->\", s)\n",
    "    s = re.sub(r\"(\\d+)\\s*\\^\\s*(\\d+)\", r\"\\1^\\2\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    sentences = re.split(r\"[.!?]\", s)\n",
    "    seen = set()\n",
    "    deduped = []\n",
    "    for sent in sentences:\n",
    "        sent = sent.strip()\n",
    "        if sent and sent not in seen:\n",
    "            seen.add(sent)\n",
    "            deduped.append(sent)\n",
    "    s = \". \".join(deduped)\n",
    "    return s\n",
    "\n",
    "df[\"full_text\"] = df[\"full_text\"].apply(clean_text)\n",
    "df = df.drop_duplicates(subset=[\"full_text\"]).reset_index(drop=True)\n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "KEYWORDS = [ \"dp\",\"greedy\",\"binary search\",\"two pointers\",\"sliding window\", \"recursion\",\"backtracking\",\"divide and conquer\",\"bitmask\", \"array\",\"string\",\"stack\",\"queue\",\"heap\",\"priority queue\", \"hashmap\",\"set\",\"tree\",\"binary tree\",\"bst\",\"segment tree\", \"fenwick\",\"trie\",\"graph\",\"dag\",\"linked list\",\"disjoint set\",\"union find\", \"bfs\",\"dfs\",\"shortest path\",\"dijkstra\",\"bellman ford\",\"floyd\", \"mst\",\"kruskal\",\"prim\",\"topological\",\"cycle\",\"bipartite\", \"modulo\",\"gcd\",\"lcm\",\"prime\",\"sieve\",\"combinatorics\",\"probability\", \"matrix\",\"prefix sum\",\"xor\",\"bitwise\", \"substring\",\"subsequence\",\"palindrome\",\"z algorithm\",\"kmp\",\"hashing\", \"simulation\",\"implementation\",\"geometry\",\"game theory\"]\n",
    "\n",
    "def numeric_features(X):\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        text = X.iloc[:, 0]\n",
    "    elif isinstance(X, pd.Series):\n",
    "        text = X\n",
    "    else:\n",
    "        text = pd.Series(X)\n",
    "    text = text.fillna(\"\").astype(str)\n",
    "    length = text.str.len().values.reshape(-1, 1)\n",
    "    math_symbols = text.str.count(r\"[=<>+\\-*/%^]\").values.reshape(-1, 1)\n",
    "    keyword_counts = np.column_stack([\n",
    "        text.str.contains(rf\"\\b{k}\\b\", case=False, regex=True).astype(int)\n",
    "        for k in KEYWORDS\n",
    "    ])\n",
    "    return np.hstack([length, math_symbols, keyword_counts])\n",
    "\n",
    "num_feat = FunctionTransformer(numeric_features, validate=False)\n",
    "\n",
    "features = ColumnTransformer([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,2),\n",
    "        min_df=3,\n",
    "        max_df=0.9,\n",
    "        sublinear_tf=True\n",
    "    ), \"full_text\"),\n",
    "    (\"numeric\", Pipeline([\n",
    "        (\"extract\", num_feat),\n",
    "        (\"scale\", StandardScaler())\n",
    "    ]), \"full_text\")\n",
    "])\n",
    "\n",
    "# SINGLE CONSISTENT SPLIT FOR EVERYTHING\n",
    "X_all = df[[\"full_text\"]]\n",
    "y_class = df[\"problem_class\"]\n",
    "y_score = df[\"problem_score\"]\n",
    "\n",
    "X_train, X_test, y_train_class, y_test_class, y_train_score, y_test_score = train_test_split(\n",
    "    X_all, y_class, y_score,\n",
    "    test_size=0.2,\n",
    "    stratify=y_class,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# CLASSIFICATION (2-STAGE)\n",
    "y_train_s1 = (y_train_class == \"hard\").astype(int)\n",
    "\n",
    "stage1 = Pipeline([\n",
    "    (\"features\", clone(features)),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=18,\n",
    "        min_samples_leaf=4,\n",
    "        min_samples_split=10,\n",
    "        class_weight={0: 1.0, 1: 1.32},\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "cv_probs = cross_val_predict(\n",
    "    stage1,\n",
    "    X_train,\n",
    "    y_train_s1,\n",
    "    cv=5,\n",
    "    method=\"predict_proba\",\n",
    "    n_jobs=-1\n",
    ")[:, 1]\n",
    "\n",
    "best_acc = -1\n",
    "best_threshold = 0.5\n",
    "for t in np.linspace(0.3, 0.7, 100):\n",
    "    preds = (cv_probs >= t).astype(int)\n",
    "    acc = accuracy_score(y_train_s1, preds)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_threshold = t\n",
    "\n",
    "HARD_T = best_threshold\n",
    "print(f\"Frozen HARD threshold (CV): {HARD_T:.4f}\")\n",
    "\n",
    "stage1.fit(X_train, y_train_s1)\n",
    "hard_proba_test = stage1.predict_proba(X_test)[:, 1]\n",
    "hard_pred_test = hard_proba_test >= HARD_T\n",
    "\n",
    "mask_train_s2 = y_train_class != \"hard\"\n",
    "mask_test_s2  = ~hard_pred_test\n",
    "\n",
    "X_train_s2 = X_train.loc[mask_train_s2]\n",
    "y_train_s2 = y_train_class.loc[mask_train_s2]\n",
    "\n",
    "X_test_s2 = X_test.loc[mask_test_s2]\n",
    "\n",
    "stage2 = Pipeline([\n",
    "    (\"features\", clone(features)),\n",
    "    (\"clf\", LinearSVC(\n",
    "        C=0.732,\n",
    "        class_weight={\n",
    "            \"easy\": 1.3,\n",
    "            \"medium\": 1.0\n",
    "        },\n",
    "        max_iter=10000\n",
    "    ))\n",
    "])\n",
    "\n",
    "stage2.fit(X_train_s2, y_train_s2)\n",
    "stage2_pred_test = stage2.predict(X_test_s2)\n",
    "\n",
    "final_pred_class = np.array([\"hard\"] * len(X_test), dtype=object)\n",
    "final_pred_class[mask_test_s2] = stage2_pred_test\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_class, final_pred_class))\n",
    "print(confusion_matrix(y_test_class, final_pred_class))\n",
    "print(classification_report(y_test_class, final_pred_class))\n",
    "from sklearn.linear_model import Ridge\n",
    "regressors = {}\n",
    "for cls in [\"easy\", \"medium\", \"hard\"]:\n",
    "    mask_cls_train = (y_train_class == cls)\n",
    "    X_cls_train = X_train.loc[mask_cls_train, [\"full_text\"]]\n",
    "    y_cls_train = y_train_score.loc[mask_cls_train]\n",
    "\n",
    "    reg_pipe = Pipeline([\n",
    "        (\"features\", clone(features)),\n",
    "        (\"to_dense\", FunctionTransformer(sparse_to_dense, accept_sparse=True)),\n",
    "        (\"reg\", Ridge(alpha=1.0))\n",
    "    ])\n",
    "    \n",
    "    reg_pipe.fit(X_cls_train, y_cls_train)\n",
    "    regressors[cls] = reg_pipe\n",
    "\n",
    "def predict_class_and_score_batch(X_text, classifier_stage1, classifier_stage2, hard_threshold, regressors):\n",
    "    # Stage1 hard vs not-hard\n",
    "    hard_proba = classifier_stage1.predict_proba(X_text)[:, 1]\n",
    "    hard_mask = hard_proba >= hard_threshold\n",
    "    pred_not_hard = classifier_stage2.predict(X_text[~hard_mask])\n",
    "    final_classes = np.array([\"hard\"] * len(X_text), dtype=object)\n",
    "    final_classes[~hard_mask] = pred_not_hard\n",
    "\n",
    "   \n",
    "    scores = np.zeros(len(X_text), dtype=float)\n",
    "    for cls in [\"easy\", \"medium\", \"hard\"]:\n",
    "        idx = np.where(final_classes == cls)[0]\n",
    "        if len(idx) > 0:\n",
    "            raw_scores = regressors[cls].predict(X_text.iloc[idx])\n",
    "            if cls == \"easy\":\n",
    "                scores[idx] = np.minimum(raw_scores, 2.8)\n",
    "            elif cls == \"medium\":\n",
    "                scores[idx] = np.clip(raw_scores, 2.9, 5.6)\n",
    "            elif cls == \"hard\":\n",
    "                scores[idx] = np.clip(raw_scores, 5.6, 10.0)\n",
    "\n",
    "    return final_classes, scores\n",
    "\n",
    "final_classes_test, final_scores_test = predict_class_and_score_batch(\n",
    "    X_test, stage1, stage2, HARD_T, regressors\n",
    ")\n",
    "\n",
    "mae = mean_absolute_error(y_test_score, final_scores_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_score, final_scores_test))\n",
    "print(f\"Score MAE (test): {mae:.4f}\")\n",
    "print(f\"Score RMSE (test): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2cbf64-d1fd-4df8-a931-a2e356037f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(stage1, \"stage1_hard_classifier.pkl\")\n",
    "joblib.dump(HARD_T, \"hard_threshold.pkl\")\n",
    "joblib.dump(stage2, \"stage2_easy_medium.pkl\")\n",
    "joblib.dump(regressors, \"score_regressors.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d935961-c83c-4ac4-acff-198dbff439e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"problem_class\").agg(\n",
    "    count=(\"problem_score\", \"count\"),\n",
    "    mn=(\"problem_score\", \"min\"),\n",
    "    mx=(\"problem_score\", \"max\"),\n",
    "    mean=(\"problem_score\", \"mean\"),\n",
    "    std=(\"problem_score\", \"std\"),\n",
    "    length_mean=(\"full_text\", lambda x: x.str.len().mean())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4e169-4f54-4c8f-b92b-f78d67a19aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
